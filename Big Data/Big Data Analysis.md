# Big Data Analysis
<!-- @author 2019-10-12 -->

## 计算引擎
在国外一些社区，有很多人将大数据的计算引擎分成了`4`代，当然，也有很多人不会认同。我们先姑且这么认为和讨论。

首先第一代的计算引擎，无疑就是`Hadoop`承载的`MapReduce`。这里大家应该都不会对`MapReduce`陌生，它将计算分为两个阶段，分别为`Map`和`Reduce`。对于上层应用来说，就不得不想方设法去拆分算法，甚至于不得不在上层应用实现多个`Job`的串联，以完成一个完整的算法，例如迭代计算。

由于这样的弊端，催生了支持`DAG`（有向无环图）框架的产生。因此，支持`DAG`的框架被划分为第二代计算引擎。如`Tez`以及更上层的`Oozie`。这里我们不去细究各种`DAG`实现之间的区别，不过对于当时的`Tez`和`Oozie`来说，大多还是批处理的任务。

接下来就是以`Spark`为代表的第三代的计算引擎。第三代计算引擎的特点主要是`Job`内部的`DAG`支持（不跨越`Job`），以及强调的实时计算。在这里，很多人也会认为第三代计算引擎也能够很好的运行批处理的`Job`。

随着第三代计算引擎的出现，促进了上层应用快速发展，例如各种迭代计算的性能以及对流计算和`SQL`等的支持。`Flink`的诞生就被归在了第四代。这应该主要表现在`Flink`对流计算的支持，以及更一步的实时性上面。当然`Flink`也可以支持`Batch`的任务，以及`DAG`的运算。

## 数据实时处理
个人对数据实时处理的理解为：数据从生成->实时采集->实时缓存存储->（准）实时计算->实时落地->实时展示->实时分析。这一个流程线下来，处理数据的速度在秒级甚至毫秒级。

数据实时处理有什么意义呢？我们得到数据可以进行数据分析，利用数据统计方法，从错综复杂的数据关系中梳理出事物的联系，比如发展趋势、影响因素、因果关系等。甚至建立一些BI，对一些数据的有用信息进行可视化呈现，并形成数据故事。

### ETL，是英文Extract-Transform-Load的缩写，用来描述将数据从来源端经过抽取（extract）、转换（transform）、加载（load）至目的端的过程。ETL一词较常用在数据仓库，但其对象并不限于数据仓库。

过程 : 抽取、清洗、转换、装载

ETL是将业务系统的数据经过抽取、清洗转换之后加载到数据仓库的过程，目的是将企业中的分散、零乱、标准不统一的数据整合到一起，为企业的决策提供分析依据，ETL是BI（商业智能）项目重要的一个环节。

- 数据仓库（DW）
- 决策支持系统（DSS）
- 在线分析处理（OLAP）
- 数据挖掘（DM）
- 商业智能（BI）

## OLTP & OLAP
业务类系统主要供基层人员使用，进行一线业务操作，通常被称为OLTP（On-Line Transaction Processing，联机事务处理）。

数据分析的目标则是探索并挖掘数据价值，作为企业高层进行决策的参考，通常被称为OLAP（On-Line Analytical Processing，联机分析处理）。

从功能角度来看，OLTP负责基本业务的正常运转，而业务数据积累时所产生的价值信息则被OLAP不断呈现，企业高层通过参考这些信息会不断调整经营方针，也会促进基础业务的不断优化，这是OLTP与OLAP最根本的区别（其他OLTP与OLAP的差别各位可以自行网上搜索，这里不再啰嗦）。

[数据流处理](https://blog.csdn.net/zlging309/article/details/9830307?utm_source=blogxgwz7)